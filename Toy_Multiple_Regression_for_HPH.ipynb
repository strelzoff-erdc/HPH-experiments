{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set of Toy Multiple Regression Problems for HPH development (and general interest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_friedman1,make_friedman2,make_friedman3, make_regression\n",
    "from sklearn.linear_model import LinearRegression, Ridge,MultiTaskLasso,MultiTaskElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import RadiusNeighborsRegressor,KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up a linear multiple regression problem using SKEARN \"make_regression\" function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.572583</td>\n",
       "      <td>-0.571179</td>\n",
       "      <td>1.797687</td>\n",
       "      <td>0.640843</td>\n",
       "      <td>133.362376</td>\n",
       "      <td>53.348308</td>\n",
       "      <td>202.145002</td>\n",
       "      <td>110.546070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.513196</td>\n",
       "      <td>1.217959</td>\n",
       "      <td>-1.104863</td>\n",
       "      <td>0.220541</td>\n",
       "      <td>-40.926813</td>\n",
       "      <td>-17.096546</td>\n",
       "      <td>-34.122116</td>\n",
       "      <td>-21.819102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.677875</td>\n",
       "      <td>-2.703232</td>\n",
       "      <td>0.189582</td>\n",
       "      <td>1.001046</td>\n",
       "      <td>63.650521</td>\n",
       "      <td>30.885570</td>\n",
       "      <td>-107.538471</td>\n",
       "      <td>-7.989816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.978373</td>\n",
       "      <td>0.195845</td>\n",
       "      <td>-0.539760</td>\n",
       "      <td>-0.778305</td>\n",
       "      <td>-91.537221</td>\n",
       "      <td>-70.295644</td>\n",
       "      <td>-148.930892</td>\n",
       "      <td>-62.683464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.757508</td>\n",
       "      <td>0.614167</td>\n",
       "      <td>-0.112328</td>\n",
       "      <td>-0.220970</td>\n",
       "      <td>0.302214</td>\n",
       "      <td>38.655431</td>\n",
       "      <td>87.921205</td>\n",
       "      <td>4.225219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3        x4          y1         y2          y3  \\\n",
       "0  0.572583 -0.571179  1.797687  0.640843  133.362376  53.348308  202.145002   \n",
       "1 -0.513196  1.217959 -1.104863  0.220541  -40.926813 -17.096546  -34.122116   \n",
       "2  0.677875 -2.703232  0.189582  1.001046   63.650521  30.885570 -107.538471   \n",
       "3 -0.978373  0.195845 -0.539760 -0.778305  -91.537221 -70.295644 -148.930892   \n",
       "4  0.757508  0.614167 -0.112328 -0.220970    0.302214  38.655431   87.921205   \n",
       "\n",
       "           y4  \n",
       "0  110.546070  \n",
       "1  -21.819102  \n",
       "2   -7.989816  \n",
       "3  -62.683464  \n",
       "4    4.225219  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Trivial Linear Multiple Regression Problem with a little Noise (0.1)\n",
    "\n",
    "X,Y = make_regression(n_samples=1000, n_features=4, n_informative=4, n_targets=4,noise=0.1,random_state=42)\n",
    "\n",
    "#let's make pandas in case we need it\n",
    "X_df = pd.DataFrame(X,columns=['x1','x2','x3','x4'])\n",
    "Y_df = pd.DataFrame(Y, columns=['y1','y2','y3','y4'])\n",
    "linear_df = pd.concat([X_df,Y_df],axis=1)\n",
    "linear_df.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split for training/testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y_scaled, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale everything using standard scaler - good practice for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaler = StandardScaler()\n",
    "X_train_scaled = x_scaler.fit_transform(X_train)\n",
    "X_test_scaled = x_scaler.transform(X_test)\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "Y_train_scaled = y_scaler.fit_transform(Y_train)\n",
    "Y_test_scaled = y_scaler.transform(Y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Several SKlearn Models - Plus XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#several SKLEARN models which support multiple regression\n",
    "\n",
    "#Note Multi-output Regressor can allow support for many single-regression models - SVR is one of the most powerful\n",
    "\n",
    "names = [\"LinearRegression\", \"KNeighborsRegressor\",  \n",
    "         \"DecisionTreeRegressor\", \"MultiTaskLasso\", \"MultiTaskElasticNet\", \n",
    "         \"Ridge\", \"MLPRegressor\", \"MultiOutputRegressor(SVR())\",\"MultiOutputRegressor(XGBRegressor())\"]\n",
    "\n",
    "regressors = [\n",
    "    LinearRegression(),\n",
    "    KNeighborsRegressor(),\n",
    "    DecisionTreeRegressor(),\n",
    "    MultiTaskLasso(alpha=0.01),\n",
    "    MultiTaskElasticNet(alpha=0.01),\n",
    "    Ridge(alpha=0.05),\n",
    "    MLPRegressor(hidden_layer_sizes=(5,),\n",
    "                                       activation='relu',\n",
    "                                       solver='adam',\n",
    "                                       learning_rate='adaptive',\n",
    "                                       max_iter=1000,\n",
    "                                       learning_rate_init=0.01,\n",
    "                                       alpha=0.01),\n",
    "    MultiOutputRegressor(SVR(kernel='linear', C=10.0)),\n",
    "    MultiOutputRegressor(XGBRegressor(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75,\n",
    "                           colsample_bytree=1, max_depth=7))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training  LinearRegression\n",
      "training  KNeighborsRegressor\n",
      "training  DecisionTreeRegressor\n",
      "training  MultiTaskLasso\n",
      "training  MultiTaskElasticNet\n",
      "training  Ridge\n",
      "training  MLPRegressor\n",
      "training  MultiOutputRegressor(SVR())\n",
      "training  MultiOutputRegressor(XGBRegressor())\n"
     ]
    }
   ],
   "source": [
    "mse = {} \n",
    "for name, clf in zip(names, regressors):\n",
    "        print(\"training \",name)\n",
    "        clf.fit(X_train_scaled, Y_train_scaled)\n",
    "        mse[name] = mean_squared_error(Y_test_scaled, clf.predict(X_test_scaled))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LinearRegression', 1.6801173293002426e-06),\n",
       " ('Ridge', 1.688384444118822e-06),\n",
       " ('MultiTaskElasticNet', 8.865890093355445e-05),\n",
       " ('MultiTaskLasso', 9.122255569091759e-05),\n",
       " ('MultiOutputRegressor(SVR())', 0.0009746860904641888),\n",
       " ('MLPRegressor', 0.005245655963964053),\n",
       " ('MultiOutputRegressor(XGBRegressor())', 0.017870360224913985),\n",
       " ('KNeighborsRegressor', 0.036867841893117634),\n",
       " ('DecisionTreeRegressor', 0.13898775841571587)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTES\n",
    "# simple linear models (linear, ridge, lasso) have few parameters and do better with a simple linear problem\n",
    "#\n",
    "# SVR (support vector regression) is super-powerful but scales poorly with more data and is very sensitive to it's hyperparameters\n",
    "#\n",
    "# MPL (neural networks) is theoretically the most powerful but requires by far the most fiddling with hyper-parameters\n",
    "#\n",
    "# tree-based models seem to be overfitting this simple dataset\n",
    "\n",
    "\n",
    "sorted(mse.items(), key=lambda kv: kv[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up a hard Non-linear Problem using SKLEARN \"make_friedman\" functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1,y1 = make_friedman1(n_samples=1000, n_features=5, noise=0.1, random_state=42)\n",
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2,y2 = make_friedman2(n_samples=1000,  noise=0.1, random_state=42)\n",
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3,y3 = make_friedman3(n_samples=1000,  noise=0.1, random_state=42)\n",
    "X3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 13)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#13 inputs\n",
    "Xnl = np.hstack((X1,X2,X3))\n",
    "Xnl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 6)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make some brutal non-linear relationships to infer\n",
    "Ynl = np.vstack((y1,y2,y3,y1*y2,y2*y3,y1*y2)).T\n",
    "Ynl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.374540</td>\n",
       "      <td>0.950714</td>\n",
       "      <td>0.731994</td>\n",
       "      <td>0.598658</td>\n",
       "      <td>0.156019</td>\n",
       "      <td>37.454012</td>\n",
       "      <td>1678.777388</td>\n",
       "      <td>0.731994</td>\n",
       "      <td>6.986585</td>\n",
       "      <td>37.454012</td>\n",
       "      <td>1678.777388</td>\n",
       "      <td>0.731994</td>\n",
       "      <td>6.986585</td>\n",
       "      <td>16.778564</td>\n",
       "      <td>1229.558301</td>\n",
       "      <td>1.673191</td>\n",
       "      <td>20630.222800</td>\n",
       "      <td>2057.285942</td>\n",
       "      <td>20630.222800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.155995</td>\n",
       "      <td>0.058084</td>\n",
       "      <td>0.866176</td>\n",
       "      <td>0.601115</td>\n",
       "      <td>0.708073</td>\n",
       "      <td>15.601864</td>\n",
       "      <td>380.500750</td>\n",
       "      <td>0.058084</td>\n",
       "      <td>9.661761</td>\n",
       "      <td>15.601864</td>\n",
       "      <td>380.500750</td>\n",
       "      <td>0.058084</td>\n",
       "      <td>9.661761</td>\n",
       "      <td>12.278795</td>\n",
       "      <td>27.084120</td>\n",
       "      <td>0.987408</td>\n",
       "      <td>332.560345</td>\n",
       "      <td>26.743077</td>\n",
       "      <td>332.560345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020584</td>\n",
       "      <td>0.969910</td>\n",
       "      <td>0.832443</td>\n",
       "      <td>0.212339</td>\n",
       "      <td>0.181825</td>\n",
       "      <td>60.111501</td>\n",
       "      <td>1282.391023</td>\n",
       "      <td>0.020584</td>\n",
       "      <td>10.699099</td>\n",
       "      <td>60.111501</td>\n",
       "      <td>1282.391023</td>\n",
       "      <td>0.020584</td>\n",
       "      <td>10.699099</td>\n",
       "      <td>5.828467</td>\n",
       "      <td>65.591539</td>\n",
       "      <td>0.353135</td>\n",
       "      <td>382.298125</td>\n",
       "      <td>23.162659</td>\n",
       "      <td>382.298125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.183405</td>\n",
       "      <td>0.304242</td>\n",
       "      <td>0.524756</td>\n",
       "      <td>0.431945</td>\n",
       "      <td>0.291229</td>\n",
       "      <td>83.244264</td>\n",
       "      <td>472.546861</td>\n",
       "      <td>0.181825</td>\n",
       "      <td>2.834045</td>\n",
       "      <td>83.244264</td>\n",
       "      <td>472.546861</td>\n",
       "      <td>0.181825</td>\n",
       "      <td>2.834045</td>\n",
       "      <td>7.623226</td>\n",
       "      <td>119.677802</td>\n",
       "      <td>0.846805</td>\n",
       "      <td>912.330974</td>\n",
       "      <td>101.343768</td>\n",
       "      <td>912.330974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.611853</td>\n",
       "      <td>0.139494</td>\n",
       "      <td>0.292145</td>\n",
       "      <td>0.366362</td>\n",
       "      <td>0.456070</td>\n",
       "      <td>30.424224</td>\n",
       "      <td>982.920600</td>\n",
       "      <td>0.431945</td>\n",
       "      <td>3.912291</td>\n",
       "      <td>30.424224</td>\n",
       "      <td>982.920600</td>\n",
       "      <td>0.431945</td>\n",
       "      <td>3.912291</td>\n",
       "      <td>9.511135</td>\n",
       "      <td>425.610182</td>\n",
       "      <td>1.453350</td>\n",
       "      <td>4048.035749</td>\n",
       "      <td>618.560655</td>\n",
       "      <td>4048.035749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3        x4        x5         x6           x7  \\\n",
       "0  0.374540  0.950714  0.731994  0.598658  0.156019  37.454012  1678.777388   \n",
       "1  0.155995  0.058084  0.866176  0.601115  0.708073  15.601864   380.500750   \n",
       "2  0.020584  0.969910  0.832443  0.212339  0.181825  60.111501  1282.391023   \n",
       "3  0.183405  0.304242  0.524756  0.431945  0.291229  83.244264   472.546861   \n",
       "4  0.611853  0.139494  0.292145  0.366362  0.456070  30.424224   982.920600   \n",
       "\n",
       "         x8         x9        x10          x11       x12        x13  \\\n",
       "0  0.731994   6.986585  37.454012  1678.777388  0.731994   6.986585   \n",
       "1  0.058084   9.661761  15.601864   380.500750  0.058084   9.661761   \n",
       "2  0.020584  10.699099  60.111501  1282.391023  0.020584  10.699099   \n",
       "3  0.181825   2.834045  83.244264   472.546861  0.181825   2.834045   \n",
       "4  0.431945   3.912291  30.424224   982.920600  0.431945   3.912291   \n",
       "\n",
       "          y1           y2        y3            y4           y5            y6  \n",
       "0  16.778564  1229.558301  1.673191  20630.222800  2057.285942  20630.222800  \n",
       "1  12.278795    27.084120  0.987408    332.560345    26.743077    332.560345  \n",
       "2   5.828467    65.591539  0.353135    382.298125    23.162659    382.298125  \n",
       "3   7.623226   119.677802  0.846805    912.330974   101.343768    912.330974  \n",
       "4   9.511135   425.610182  1.453350   4048.035749   618.560655   4048.035749  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's make pandas in case we need it\n",
    "X_nl_df = pd.DataFrame(Xnl,columns=['x'+str(i+1) for i in range(0,13)])\n",
    "Y_nl_df = pd.DataFrame(Ynl, columns=['y'+str(i+1) for i in range(0,6)])\n",
    "nl_df = pd.concat([X_nl_df ,Y_nl_df],axis=1)\n",
    "nl_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split for training/testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(Xnl, Ynl, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale everything using standard scaler - good practice for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaler_nl = StandardScaler()\n",
    "X_train_scaled_nl = x_scaler_nl.fit_transform(X_train)\n",
    "X_test_scaled_nl = x_scaler_nl.transform(X_test)\n",
    "\n",
    "y_scaler_nl = StandardScaler()\n",
    "Y_train_scaled_nl = y_scaler_nl.fit_transform(Y_train)\n",
    "Y_test_scaled_nl = y_scaler_nl.transform(Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 13)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled_nl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training  LinearRegression\n",
      "training  KNeighborsRegressor\n",
      "training  DecisionTreeRegressor\n",
      "training  MultiTaskLasso\n",
      "training  MultiTaskElasticNet\n",
      "training  Ridge\n",
      "training  MLPRegressor\n",
      "training  MultiOutputRegressor(SVR())\n",
      "training  MultiOutputRegressor(XGBRegressor())\n"
     ]
    }
   ],
   "source": [
    "msenl = {} \n",
    "for name, clf in zip(names, regressors):\n",
    "        print(\"training \",name)\n",
    "        clf.fit(X_train_scaled_nl, Y_train_scaled_nl)\n",
    "        msenl[name] = mean_squared_error(Y_test_scaled_nl, clf.predict(X_test_scaled_nl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('MultiOutputRegressor(XGBRegressor())', 0.05278559956656891),\n",
       " ('MLPRegressor', 0.12170215887420384),\n",
       " ('KNeighborsRegressor', 0.2537543277088086),\n",
       " ('LinearRegression', 0.2591236938628191),\n",
       " ('Ridge', 0.2591262850622057),\n",
       " ('MultiTaskElasticNet', 0.2600599092054938),\n",
       " ('MultiTaskLasso', 0.2605453559159993),\n",
       " ('MultiOutputRegressor(SVR())', 0.2822419835285024),\n",
       " ('DecisionTreeRegressor', 0.3286053406230079)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTES\n",
    "# The more complex models XGBoost and MLPRegressor do a better job on the highly non-linear dataset\n",
    "# it's possible that with more fiddling MSE could be reduced to (usually required for fielding) ~0.01\n",
    "\n",
    "sorted(msenl.items(), key=lambda kv: kv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
